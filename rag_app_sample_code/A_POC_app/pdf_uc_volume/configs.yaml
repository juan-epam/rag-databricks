code_file: multi_turn_rag_chain.py
data_pipeline:
  embedding_config:
    embedding_endpoint_name: databricks-gte-large-en
    embedding_tokenizer:
      tokenizer_model_name: Alibaba-NLP/gte-large-en-v1.5
      tokenizer_source: hugging_face
  pipeline_config:
    chunker:
      config:
        chunk_overlap_tokens: 128
        chunk_size_tokens: 512
      name: langchain_recursive_char
    file_format: pdf
    parser:
      config: {}
      name: pypdf
  vectorsearch_config:
    pipeline_type: CONTINUOUS
destination_tables:
  chunked_docs_table_name: '`main`.`test_lt`.`deepseek_rag_poc_chunked_docs_gold`'
  parsed_docs_table_name: '`main`.`test_lt`.`deepseek_rag_poc_parsed_docs_silver`'
  raw_files_table_name: '`main`.`test_lt`.`deepseek_rag_poc_raw_files_bronze`'
  vectorsearch_index_name: main.test_lt.deepseek_rag_poc_chunked_docs_gold_index
  vectorsearch_index_table_name: '`main`.`test_lt`.`deepseek_rag_poc_chunked_docs_gold_index`'
global_config:
  EVALUATION_SET_FQN: '`main`.`test_lt`.deepseek_rag_evaluation_set'
  MLFLOW_EXPERIMENT_NAME: /Users/juan_tello@epam.com/deepseek_rag
  POC_CHAIN_RUN_NAME: poc
  POC_DATA_PIPELINE_RUN_NAME: data_pipeline_poc
  RAG_APP_NAME: deepseek_rag
  SOURCE_PATH: /Volumes/main/test_lt/docs
  UC_CATALOG: main
  UC_MODEL_NAME: main.test_lt.deepseek_rag
  UC_SCHEMA: test_lt
  VECTOR_SEARCH_ENDPOINT: juan_tello_vector_search
  user_email: juan_tello@epam.com
  user_name: juan_tello
rag_chain_config:
  databricks_resources:
    llm_endpoint_name: databricks-meta-llama-3-3-70b-instruct
    vector_search_endpoint_name: juan_tello_vector_search
  input_example:
    messages:
    - content: What is RAG?
      role: user
  llm_config:
    llm_parameters:
      max_tokens: 1500
      temperature: 0.01
    llm_system_prompt_template: 'You are an assistant that answers questions. Use
      the following pieces of retrieved context to answer the question. Some pieces
      of context may be irrelevant, in which case you should not use them to form
      the answer.


      Context: {context}'
  retriever_config:
    chunk_template: 'From doc_uri: {document_uri}\nPassage: {chunk_text}\n'
    data_pipeline_tag: poc
    parameters:
      k: 10
      query_type: hybrid
    schema:
      chunk_text: chunked_text
      document_uri: path
      primary_key: chunk_id
    vector_search_index: main.test_lt.deepseek_rag_poc_chunked_docs_gold_index
